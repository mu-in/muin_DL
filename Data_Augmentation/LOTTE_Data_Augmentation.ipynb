{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LOTTE_Data_Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsFDW46WOSTZ"
      },
      "source": [
        "### python .xml to .json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZzzXZboMVGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b51a95-1be0-4763-f1b2-0a9ffb57ed95"
      },
      "source": [
        "!pip install xmltodict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5agxVuDOiOT",
        "outputId": "3ed12463-2133-47b2-957b-575e7a660f37"
      },
      "source": [
        "import json\n",
        "import xmltodict\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Lotte_sample/10054_60_s_9_meta.xml\",'r') as f:\n",
        "    xmlString = f.read()\n",
        "\n",
        "jsonString = json.dumps(xmltodict.parse(xmlString), indent=4)\n",
        " \n",
        "print(\"\\nJSON output(output.json):\")\n",
        "print(jsonString)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "JSON output(output.json):\n",
            "{\n",
            "    \"comp_cd\": {\n",
            "        \"identifier\": {\n",
            "            \"identifier\": \"10054_60_s_9.jpg\",\n",
            "            \"copyright\": \"LOTTE Data Communication Company\"\n",
            "        },\n",
            "        \"div_cd\": {\n",
            "            \"item_cd\": \"03021200001\",\n",
            "            \"item_no\": \"10054\",\n",
            "            \"div_l\": \"\\uc8fc\\ub958\",\n",
            "            \"div_m\": \"\\uae30\\ud0c0\\uc8fc\\ub958\",\n",
            "            \"div_s\": \"\\uce75\\ud14c\\uc77c\",\n",
            "            \"div_n\": \"\\uce75\\ud14c\\uc77c\",\n",
            "            \"comp_nm\": \"\\ub86f\\ub370\\uc8fc\\ub958\",\n",
            "            \"img_prod_nm\": \"\\uc21c\\ud558\\ub9ac\\uc18c\\ub2e4\\ud1a1\\ubc14\\ub098\\ub098355ML\",\n",
            "            \"volume\": \"355ML\",\n",
            "            \"barcd\": \"8801030996231\",\n",
            "            \"width\": \"7\",\n",
            "            \"length\": \"7\",\n",
            "            \"height\": \"12\",\n",
            "            \"nutrition_info\": \"{\\\"1\\ud68c\\uc81c\\uacf5\\ub7c9\\\":\\\"\\\",\\\"\\ucd1d\\ub0b4\\uc6a9\\ub7c9(g)\\\":\\\"\\\",\\\"\\ucd1d\\ub0b4\\uc6a9\\ub7c9(mL)\\\":\\\"\\\",\\\"\\uc5d0\\ub108\\uc9c0(\\u3389)\\\":\\\"\\\",\\\"\\ub2e8\\ubc31\\uc9c8(g)\\\":\\\"\\\",\\\"\\uc9c0\\ubc29(g)\\\":\\\"\\\",\\\"\\ud0c4\\uc218\\ud654\\ubb3c(g)\\\":\\\"\\\",\\\"\\ucd1d\\ub2f9\\ub958(g)\\\":\\\"\\\",\\\"\\ucd1d \\uc2dd\\uc774\\uc12c\\uc720(g)\\\":\\\"\\\",\\\"\\uce7c\\uc298(\\u338e)\\\":\\\"\\\",\\\"\\ucca0(\\u338d)\\\":\\\"\\\",\\\"\\ub9c8\\uadf8\\ub124\\uc298(\\u338e)\\\":\\\"\\uce74\\ud398\\uc778(\\u338e)\\\":\\\"\\\"\\\",\\\"\\uce7c\\ub968(\\u338e)\\\":\\\"\\\",\\\"\\ub098\\ud2b8\\ub968(\\u338e)\\\":\\\"\\\",\\\"\\ube44\\ud0c0\\ubbfc\\\":\\\"\\\",\\\"\\ucf5c\\ub808\\uc2a4\\ud14c\\ub864(\\u338e)\\\":\\\"\\\",\\\"\\ucd1d \\uc9c0\\ubc29\\uc0b0(g)\\\":\\\"\\\",}\",\n",
            "            \"#text\": \"12\"\n",
            "        },\n",
            "        \"annotation\": {\n",
            "            \"folder\": \"/119.\\uc0c1\\ud488 \\uc774\\ubbf8\\uc9c0 \\ub370\\uc774\\ud130/01.\\ub370\\uc774\\ud130/1.Training/\\uc6d0\\ucc9c\\ub370\\uc774\\ud130/\\uc8fc\\ub958/10054_\\uc21c\\ud558\\ub9ac\\uc18c\\ub2e4\\ud1a1\\ubc14\\ub098\\ub098355ML/\",\n",
            "            \"filename\": \"10054_60_s_9.jpg\",\n",
            "            \"path\": \"/119.\\uc0c1\\ud488 \\uc774\\ubbf8\\uc9c0 \\ub370\\uc774\\ud130/01.\\ub370\\uc774\\ud130/1.Training/\\uc6d0\\ucc9c\\ub370\\uc774\\ud130/\\uc8fc\\ub958/10054_\\uc21c\\ud558\\ub9ac\\uc18c\\ub2e4\\ud1a1\\ubc14\\ub098\\ub098355ML/10054_60_s_9.jpg\",\n",
            "            \"source\": {\n",
            "                \"database\": \"Unknown\"\n",
            "            },\n",
            "            \"size\": {\n",
            "                \"width\": \"2988\",\n",
            "                \"height\": \"2988\",\n",
            "                \"depth\": \"3\"\n",
            "            },\n",
            "            \"segmented\": \"0\",\n",
            "            \"object\": {\n",
            "                \"name\": \"\\uc21c\\ud558\\ub9ac\\uc18c\\ub2e4\\ud1a1\\ubc14\\ub098\\ub098355ML\",\n",
            "                \"pose\": \"Unspecified\",\n",
            "                \"truncated\": \"0\",\n",
            "                \"difficult\": \"0\",\n",
            "                \"bndbox\": {\n",
            "                    \"xmin\": \"599\",\n",
            "                    \"ymin\": \"82\",\n",
            "                    \"xmax\": \"2377\",\n",
            "                    \"ymax\": \"2893\"\n",
            "                }\n",
            "            }\n",
            "        },\n",
            "        \"#text\": \"0302\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k63LyrFmY1TC"
      },
      "source": [
        "### Image Copy & Paste Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmcfVc6iZJfh",
        "outputId": "6e322d37-aa27-4edc-c09e-dd208ca6056a"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "## paste image\n",
        "to_paste = np.full((2988, 2988, 3), 255, dtype=np.uint8) # 계산대 색으로 조정\n",
        "print(to_paste.shape)\n",
        "\n",
        "## copy image\n",
        "to_copy = cv2.imread('/content/drive/MyDrive/Lotte_sample/10094_0_m_1.jpg', cv2.IMREAD_COLOR) \n",
        "print(to_copy.shape)\n",
        "# reshape\n",
        "imageHeight, imageWidth = to_copy.shape[:2]\n",
        "\n",
        "resizeHeight = int(0.25 * imageHeight) # x 0.25 resize !!\n",
        "resizeWidth = int(0.25 * imageWidth)\n",
        "\n",
        "to_copy_resize = cv2.resize(to_copy, (resizeHeight, resizeWidth), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "## copy & paste\n",
        "to_paste[500:500+resizeHeight, 500:500+resizeWidth] = to_copy_resize \n",
        "\n",
        "cv2.imwrite(\"/content/drive/MyDrive/Lotte_sample_result/final_img.jpg\", to_paste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2988, 2988, 3)\n",
            "(2988, 2988, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR8OpvV8h2Gw"
      },
      "source": [
        "### Sample Dataset Unzip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0t-rYSTh-25",
        "outputId": "6d11976a-dd01-4a45-e667-6bccf74971f6"
      },
      "source": [
        "%cd /content/drive/MyDrive/LOTTE_sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LOTTE_sample\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cm5a5eLiFEx"
      },
      "source": [
        "!unzip -qq \"/content/drive/MyDrive/LOTTE_sample/LOTTE_sample.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbaIKcLe_0oO"
      },
      "source": [
        "### Data Augmentation Code (using Jacard Overlap)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M21ASxlh_zpH",
        "outputId": "ebdefb5e-eb12-4dfb-e5be-4196412043f3"
      },
      "source": [
        "!pip install xmltodict # xml2json 에 필요한 라이브러리 설치\n",
        "\n",
        "## code for Jacard Overlap (IOU)\n",
        "def find_intersection(set_1, set_2):\n",
        "    \"\"\"\n",
        "    Find the intersection of every box combination between two sets of boxes that are in boundary coordinates.\n",
        "\n",
        "    :param set_1: set 1, a tensor of dimensions (n1, 4)\n",
        "    :param set_2: set 2, a tensor of dimensions (n2, 4)\n",
        "    :return: intersection of each of the boxes in set 1 with respect to each of the boxes in set 2, a tensor of dimensions (n1, n2)\n",
        "    \"\"\"\n",
        "\n",
        "    # PyTorch auto-broadcasts singleton dimensions\n",
        "    lower_bounds = torch.max(set_1[:, :2].unsqueeze(1), set_2[:, :2].unsqueeze(0))  # (n1, n2, 2)\n",
        "    upper_bounds = torch.min(set_1[:, 2:].unsqueeze(1), set_2[:, 2:].unsqueeze(0))  # (n1, n2, 2)\n",
        "    intersection_dims = torch.clamp(upper_bounds - lower_bounds, min=0)  # (n1, n2, 2)\n",
        "    return intersection_dims[:, :, 0] * intersection_dims[:, :, 1]  # (n1, n2)\n",
        "\n",
        "def find_jaccard_overlap(set_1, set_2):\n",
        "    \"\"\"\n",
        "    Find the Jaccard Overlap (IoU) of every box combination between two sets of boxes that are in boundary coordinates.\n",
        "\n",
        "    :param set_1: set 1, a tensor of dimensions (n1, 4)\n",
        "    :param set_2: set 2, a tensor of dimensions (n2, 4)\n",
        "    :return: Jaccard Overlap of each of the boxes in set 1 with respect to each of the boxes in set 2, a tensor of dimensions (n1, n2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Find intersections\n",
        "    intersection = find_intersection(set_1, set_2)  # (n1, n2)\n",
        "\n",
        "    # Find areas of each box in both sets\n",
        "    areas_set_1 = (set_1[:, 2] - set_1[:, 0]) * (set_1[:, 3] - set_1[:, 1])  # (n1)\n",
        "    areas_set_2 = (set_2[:, 2] - set_2[:, 0]) * (set_2[:, 3] - set_2[:, 1])  # (n2)\n",
        "\n",
        "    # Find the union\n",
        "    # PyTorch auto-broadcasts singleton dimensions\n",
        "    union = areas_set_1.unsqueeze(1) + areas_set_2.unsqueeze(0) - intersection  # (n1, n2)\n",
        "\n",
        "    return intersection / union  # (n1, n2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (0.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwHvIyfyhNXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27e19ec-5f48-4707-a41d-516761fac6c6"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import xmltodict\n",
        "import glob\n",
        "from random import *\n",
        "import math\n",
        "import torch\n",
        "\n",
        "# to make _meta.xml information list\n",
        "file_path = \"/content/drive/MyDrive/Lotte_sample/*\" \n",
        "file_pathes = glob.glob(file_path)\n",
        "file_list = [file for file in file_pathes if file.endswith(\"_meta.xml\")]\n",
        "# print (\"file_list_py: {}\".format(file_list_py))\n",
        "\n",
        "\n",
        "## 예시) 9개의 images & annotations -> 1개의 final image & annotation\n",
        "\n",
        "## to_paste image\n",
        "to_paste = np.full((2988, 2988, 3), 255, dtype=np.uint8) # 계산대 색으로 조정\n",
        "print(to_paste.shape)\n",
        "\n",
        "# number of objects\n",
        "n_objects = 5\n",
        "# resize ratio\n",
        "resize_ratio = 0.4\n",
        "\n",
        "# # starting offset -> 3x3\n",
        "# offset = []\n",
        "# for i in range (int(math.sqrt(n_objects))):\n",
        "#     for j in range (int(math.sqrt(n_objects))):\n",
        "#         height = i * int(2988/math.sqrt(n_objects))  \n",
        "#         width = j * int(2988/math.sqrt(n_objects))\n",
        "#         offset.append([height, width])\n",
        "\n",
        "pre_boxes = torch.zeros(1, 4, dtype = torch.long) # IOU 비교를 위한 boxes \n",
        "for i in range (n_objects):\n",
        "\n",
        "    # ver_idx, hor_idx = offset[i]\n",
        "\n",
        "    # # random offset\n",
        "    # ver_idx = randint(ver_idx, ver_idx + int(2988/(math.sqrt(n_objects)*2)))\n",
        "    # hor_idx = randint(hor_idx, hor_idx + int(2988/(math.sqrt(n_objects)*2)))\n",
        "    # print(ver_idx, hor_idx)\n",
        "\n",
        "    line = file_list[i]\n",
        "\n",
        "    # .xml to .json \n",
        "    with open(line,'r') as f:\n",
        "        xmlString = f.read()\n",
        "    obj_Info = json.loads(json.dumps(xmltodict.parse(xmlString), indent=4))\n",
        "\n",
        "    # to_copy image\n",
        "    to_copy = cv2.imread(file_path[:-1] + obj_Info['comp_cd']['annotation']['filename'], cv2.IMREAD_COLOR) \n",
        "\n",
        "    imageHeight, imageWidth = to_copy.shape[:2]\n",
        "\n",
        "    resizeHeight = int(resize_ratio * imageHeight)\n",
        "    resizeWidth = int(resize_ratio * imageWidth)\n",
        "\n",
        "    to_copy_resize = cv2.resize(to_copy, (resizeHeight, resizeWidth), interpolation = cv2.INTER_CUBIC)\n",
        "   \n",
        "    # to_copy_resize image 속 object 별로 진행\n",
        "    boxes_dict = []\n",
        "    if 'dict' in str(type(obj_Info['comp_cd']['annotation']['object'])): # 이미지 속 물체가 1개일 경우, 주석 다름\n",
        "        boxes_dict.append(obj_Info['comp_cd']['annotation']['object']) # 인위적으로 리스트 안으로 넣어줌\n",
        "    else: boxes_dict =  obj_Info['comp_cd']['annotation']['object'] \n",
        "\n",
        "    boxes = []\n",
        "    for k, obj in enumerate (boxes_dict):\n",
        "\n",
        "        dict_val_box = obj['bndbox'].values()\n",
        "        list_box = list(dict_val_box)\n",
        "        org_box = list(map(int, list_box))\n",
        "        box = [round(j*resize_ratio) for j in org_box] \n",
        "        boxes.append(box)\n",
        "    \n",
        "    # random offset + IOU->occlusion 확인\n",
        "    while True:\n",
        "        ## 랜덤 좌표\n",
        "        ver_idx = randint(0, 2000)\n",
        "        hor_idx = randint(0, 2000) \n",
        "\n",
        "        ver = ver_idx\n",
        "        hor = hor_idx\n",
        "\n",
        "        new_boxes = []\n",
        "        for xmin, ymin, xmax, ymax in boxes:\n",
        "            x_min = hor\n",
        "            y_min = ver\n",
        "            x_max = hor + (xmax - xmin)\n",
        "            y_max = ver + (ymax - ymin)\n",
        "            new_boxes.append([x_min, y_min, x_max, y_max])\n",
        "            \n",
        "            hor = hor + (xmax - xmin)\n",
        "\n",
        "        # overlap 검사 실시\n",
        "        new_boxes = torch.tensor(new_boxes)\n",
        "        overlap = find_jaccard_overlap(pre_boxes, new_boxes).view([-1])\n",
        "        overlap = overlap.tolist()\n",
        "\n",
        "        check = 1\n",
        "        for a in overlap: \n",
        "            if a != 0: check = 0 \n",
        "        if check == 1: break # occlusion 발생하지 않으면 -> while 문 탈출\n",
        "    \n",
        "    # overlap 비교를 위한 pre_boxes -> new_boxes 추가\n",
        "    pre_boxes = torch.cat([pre_boxes, new_boxes], dim=0)\n",
        "    \n",
        "    # import pdb;pdb.set_trace()\n",
        "\n",
        "    # new_boxes = new_boxes.tolist() # Tensor -> list\n",
        "    # image copy & paste\n",
        "    for box in boxes:\n",
        "        to_paste[ver_idx:ver_idx+(box[3]-box[1]), hor_idx:hor_idx+(box[2]-box[0])] = \\\n",
        "                                                    to_copy_resize[box[1]:box[3], box[0]:box[2]]\n",
        "        # 같은 이미지 속의 물체들은 서로 붙여놓음\n",
        "        hor_idx = hor_idx+(box[2]-box[0])\n",
        "\n",
        "\n",
        "    # category = obj_Info['comp_cd']['div_cd']['item_cd'] # label\n",
        "    # image_path = file_path[:-1] + obj_Info['comp_cd']['annotation']['filename'] # path\n",
        "    # resolution = obj_Info['comp_cd']['annotation']['size']\n",
        "    # break\n",
        "\n",
        "# save final image\n",
        "cv2.imwrite(\"/content/drive/MyDrive/Lotte_sample_result/final_img.jpg\", to_paste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2988, 2988, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHopMaFP7csB"
      },
      "source": [
        "### Test Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71MBX7-A0kqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8fdfc18-f53a-4bf0-c12e-45c83ad3b776"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import xmltodict\n",
        "import glob\n",
        "from random import *\n",
        "import math\n",
        "import torch\n",
        "\n",
        "# to make _meta.xml information list\n",
        "file_path = \"/content/drive/MyDrive/Lotte_sample/*\" \n",
        "file_pathes = glob.glob(file_path)\n",
        "file_list = [file for file in file_pathes if file.endswith(\"_meta.xml\")]\n",
        "# print (\"file_list_py: {}\".format(file_list_py))\n",
        "\n",
        "\n",
        "## 예시) 9개의 images & annotations -> 1개의 final image & annotation\n",
        "\n",
        "## to_paste image\n",
        "to_paste = np.full((2988, 2988, 3), 255, dtype=np.uint8) # 계산대 색으로 조정\n",
        "print(to_paste.shape)\n",
        "\n",
        "# number of objects\n",
        "n_objects = 5\n",
        "# resize ratio\n",
        "resize_ratio = 0.4\n",
        "\n",
        "# # starting offset -> 3x3\n",
        "# offset = []\n",
        "# for i in range (int(math.sqrt(n_objects))):\n",
        "#     for j in range (int(math.sqrt(n_objects))):\n",
        "#         height = i * int(2988/math.sqrt(n_objects))  \n",
        "#         width = j * int(2988/math.sqrt(n_objects))\n",
        "#         offset.append([height, width])\n",
        "\n",
        "pre_boxes = torch.zeros(1, 4, dtype = torch.long) # IOU 비교를 위한 boxes \n",
        "for i in range (n_objects):\n",
        "\n",
        "    # ver_idx, hor_idx = offset[i]\n",
        "\n",
        "    # # random offset\n",
        "    # ver_idx = randint(ver_idx, ver_idx + int(2988/(math.sqrt(n_objects)*2)))\n",
        "    # hor_idx = randint(hor_idx, hor_idx + int(2988/(math.sqrt(n_objects)*2)))\n",
        "    # print(ver_idx, hor_idx)\n",
        "\n",
        "    line = file_list[i]\n",
        "\n",
        "    # .xml to .json \n",
        "    with open(line,'r') as f:\n",
        "        xmlString = f.read()\n",
        "    obj_Info = json.loads(json.dumps(xmltodict.parse(xmlString), indent=4))\n",
        "\n",
        "    # to_copy image\n",
        "    to_copy = cv2.imread(file_path[:-1] + obj_Info['comp_cd']['annotation']['filename'], cv2.IMREAD_COLOR) \n",
        "\n",
        "    imageHeight, imageWidth = to_copy.shape[:2]\n",
        "\n",
        "    resizeHeight = int(resize_ratio * imageHeight)\n",
        "    resizeWidth = int(resize_ratio * imageWidth)\n",
        "\n",
        "    to_copy_resize = cv2.resize(to_copy, (resizeHeight, resizeWidth), interpolation = cv2.INTER_CUBIC)\n",
        "   \n",
        "    # to_copy_resize image 속 object 별로 진행\n",
        "    boxes_dict = []\n",
        "    if 'dict' in str(type(obj_Info['comp_cd']['annotation']['object'])): # 이미지 속 물체가 1개일 경우, 주석 다름\n",
        "        boxes_dict.append(obj_Info['comp_cd']['annotation']['object']) # 인위적으로 리스트 안으로 넣어줌\n",
        "    else: boxes_dict =  obj_Info['comp_cd']['annotation']['object'] \n",
        "\n",
        "    boxes = []\n",
        "    for k, obj in enumerate (boxes_dict):\n",
        "\n",
        "        dict_val_box = obj['bndbox'].values()\n",
        "        list_box = list(dict_val_box)\n",
        "        org_box = list(map(int, list_box))\n",
        "        box = [round(j*resize_ratio) for j in org_box] \n",
        "        boxes.append(box)\n",
        "    \n",
        "    # random offset + IOU->occlusion 확인\n",
        "    while True:\n",
        "        ## 랜덤 좌표\n",
        "        ver_idx = randint(0, 2000)\n",
        "        hor_idx = randint(0, 2000) \n",
        "\n",
        "        ver = ver_idx\n",
        "        hor = hor_idx\n",
        "\n",
        "        new_boxes = []\n",
        "        for xmin, ymin, xmax, ymax in boxes:\n",
        "            x_min = hor\n",
        "            y_min = ver\n",
        "            x_max = hor + (xmax - xmin)\n",
        "            y_max = ver + (ymax - ymin)\n",
        "            new_boxes.append([x_min, y_min, x_max, y_max])\n",
        "            \n",
        "            hor = hor + (xmax - xmin)\n",
        "\n",
        "        # overlap 검사 실시\n",
        "        new_boxes = torch.tensor(new_boxes)\n",
        "        overlap = find_jaccard_overlap(pre_boxes, new_boxes).view([-1])\n",
        "        overlap = overlap.tolist()\n",
        "\n",
        "        check = 1\n",
        "        for a in overlap: \n",
        "            if a != 0: check = 0 \n",
        "        if check == 1: break # occlusion 발생하지 않으면 -> while 문 탈출\n",
        "    \n",
        "    # overlap 비교를 위한 pre_boxes -> new_boxes 추가\n",
        "    pre_boxes = torch.cat([pre_boxes, new_boxes], dim=0)\n",
        "    \n",
        "    # import pdb;pdb.set_trace()\n",
        "\n",
        "    # new_boxes = new_boxes.tolist() # Tensor -> list\n",
        "    # image copy & paste\n",
        "    for box in boxes:\n",
        "        to_paste[ver_idx:ver_idx+(box[3]-box[1]), hor_idx:hor_idx+(box[2]-box[0])] = \\\n",
        "                                                    to_copy_resize[box[1]:box[3], box[0]:box[2]]\n",
        "        # 같은 이미지 속의 물체들은 서로 붙여놓음\n",
        "        hor_idx = hor_idx+(box[2]-box[0])\n",
        "\n",
        "\n",
        "    # category = obj_Info['comp_cd']['div_cd']['item_cd'] # label\n",
        "    # image_path = file_path[:-1] + obj_Info['comp_cd']['annotation']['filename'] # path\n",
        "    # resolution = obj_Info['comp_cd']['annotation']['size']\n",
        "    # break\n",
        "\n",
        "# save final image\n",
        "cv2.imwrite(\"/content/drive/MyDrive/Lotte_sample_result/final_img.jpg\", to_paste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2988, 2988, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k98ZGj4TQPiz",
        "outputId": "5539ad92-06e7-46fb-a2a2-90e172300ad7"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}